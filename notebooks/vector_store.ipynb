{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, dimension: int, output_dir: str = '../vector_store'):\n",
    "        \"\"\"Initialize FAISS index and output directory\"\"\"\n",
    "        self.dimension = dimension\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "        self.chunk_map = {}\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        # Ensure the output directory exists\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "    def add_vectors(self, vectors: Dict[int, np.ndarray], chunk_map: Dict[int, Dict]):\n",
    "        \"\"\"Add vectors to the FAISS index\"\"\"\n",
    "        # Convert vectors dictionary to numpy array\n",
    "        vector_array = np.array(list(vectors.values())).astype('float32')\n",
    "\n",
    "        # Add to FAISS index\n",
    "        self.index.add(vector_array)\n",
    "\n",
    "        # Store chunk mapping\n",
    "        self.chunk_map = chunk_map\n",
    "\n",
    "        print(f\"Added {len(vectors)} vectors to index\")\n",
    "\n",
    "    def save_index(self):\n",
    "        \"\"\"Save FAISS index and chunk mapping\"\"\"\n",
    "        index_path = os.path.join(self.output_dir, 'faiss_index.idx')\n",
    "        chunk_map_path = os.path.join(self.output_dir, 'chunk_map.pkl')\n",
    "\n",
    "        # Save FAISS index\n",
    "        faiss.write_index(self.index, index_path)\n",
    "\n",
    "        # Save chunk mapping\n",
    "        with open(chunk_map_path, 'wb') as f:\n",
    "            pickle.dump(self.chunk_map, f)\n",
    "\n",
    "        print(f\"Index saved to {index_path}\")\n",
    "        print(f\"Chunk map saved to {chunk_map_path}\")\n",
    "\n",
    "    def load_index(self):\n",
    "        \"\"\"Load FAISS index and chunk mapping\"\"\"\n",
    "        index_path = os.path.join(self.output_dir, 'faiss_index.idx')\n",
    "        chunk_map_path = os.path.join(self.output_dir, 'chunk_map.pkl')\n",
    "\n",
    "        # Load FAISS index\n",
    "        self.index = faiss.read_index(index_path)\n",
    "\n",
    "        # Load chunk mapping\n",
    "        with open(chunk_map_path, 'rb') as f:\n",
    "            self.chunk_map = pickle.load(f)\n",
    "\n",
    "        print(f\"Index loaded from {index_path}\")\n",
    "        print(f\"Chunk map loaded from {chunk_map_path}\")\n",
    "\n",
    "    def search(self, query_vector: np.ndarray, k: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search for similar vectors\"\"\"\n",
    "        # Ensure query vector is in correct format\n",
    "        query_vector = query_vector.reshape(1, -1).astype('float32')\n",
    "\n",
    "        # Search\n",
    "        distances, indices = self.index.search(query_vector, k)\n",
    "\n",
    "        # Get results\n",
    "        results = []\n",
    "        for i, idx in enumerate(indices[0]):\n",
    "            if idx < len(self.chunk_map):  # Check if index is valid\n",
    "                result = self.chunk_map[idx].copy()\n",
    "                result['distance'] = float(distances[0][i])\n",
    "                results.append(result)\n",
    "\n",
    "        return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding vectors to FAISS index...\n",
      "Added 1454 vectors to index\n",
      "Saving FAISS index and chunk map...\n",
      "Index saved to ../vector_store/faiss_index.idx\n",
      "Chunk map saved to ../vector_store/chunk_map.pkl\n",
      "\n",
      "Vector Store Statistics:\n",
      "Total vectors in index: 1454\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = '../embeddings'\n",
    "    output_dir = '../vector_store'\n",
    "\n",
    "    # Load combined vectors from input directory\n",
    "    with open(os.path.join(input_dir, 'vectors.pkl'), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    vectors = data['vectors']\n",
    "    chunk_map = data['chunk_map']\n",
    "\n",
    "    # Initialize vector store\n",
    "    vector_store = VectorStore(\n",
    "        dimension=len(next(iter(vectors.values()))), output_dir=output_dir\n",
    "    )\n",
    "\n",
    "    # Add vectors to FAISS index\n",
    "    print(\"Adding vectors to FAISS index...\")\n",
    "    vector_store.add_vectors(vectors, chunk_map)\n",
    "\n",
    "    # Save index and chunk mapping\n",
    "    print(\"Saving FAISS index and chunk map...\")\n",
    "    vector_store.save_index()\n",
    "\n",
    "    # Test index stats\n",
    "    print(\"\\nVector Store Statistics:\")\n",
    "    print(f\"Total vectors in index: {vector_store.index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content_engine_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
